{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midterm 2 - MNIST Classification\n",
    "![front_page.png](attachment:front_page.png)\n",
    "### Preparing environment and dataset:\n",
    "* pip install python-mnist\n",
    "* create folder midterm/data\n",
    "* download from https://drive.google.com/open?id=1AQwyy3xP7rjDWMPkWBW4kKOfpkIyAWt8 - 4 files\n",
    "* extract all files to ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The error of your classifier on test dataset must be better then 12.0% LeCun et al. 1998\n",
    "#### Enter your error at https://goo.gl/forms/JRDKcotcXf5LZM3I3\n",
    "#### Commit your code to github/bitbucket into folder midterm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of train images 60000\n",
      "The amount of test images 60000\n",
      "The label of random image 9 The random image is \n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      ".............@@@@@@@........\n",
      "........@@@@@@@...@@........\n",
      ".....@@@@@........@@........\n",
      "....@..............@........\n",
      "...@...............@........\n",
      "...@...............@@.......\n",
      "...@...............@@.......\n",
      "...@@..............@@.......\n",
      "....@@..............@.......\n",
      "......@..........@..@.......\n",
      "........@@@@@@@@@...@.......\n",
      "....................@@......\n",
      "....................@@......\n",
      ".....................@......\n",
      ".....................@......\n",
      ".....................@......\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "Images are binary with 28*28 =  784\n"
     ]
    }
   ],
   "source": [
    "from mnist import MNIST\n",
    "import random\n",
    "\n",
    "mndata = MNIST('.//data')\n",
    "\n",
    "trimages, trlabels = mndata.load_training()\n",
    "teimages, telabels = mndata.load_testing()\n",
    "index = random.randrange(0, len(trimages))  # choose an index ;-)\n",
    "print('The amount of train images',len(trimages))\n",
    "print('The amount of test images',len(trimages))\n",
    "print('The label of random image',trlabels[index],'The random image is',mndata.display(trimages[index]))\n",
    "print('Images are binary with 28*28 = ',len(trimages[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "37800/60000 [=================>............] - ETA: 57s - loss: 6.0892 - categorical_accuracy: 0.1965"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import idx2numpy\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras import regularizers\n",
    "from keras import metrics\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "from scipy import misc\n",
    "\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "\n",
    "X_train = idx2numpy.convert_from_file(DATA_PATH + 'train-images-idx3-ubyte')\n",
    "Y_train = idx2numpy.convert_from_file(DATA_PATH + 'train-labels-idx1-ubyte')\n",
    "X_test = idx2numpy.convert_from_file(DATA_PATH + 't10k-images-idx3-ubyte')\n",
    "Y_test = idx2numpy.convert_from_file(DATA_PATH + 't10k-labels-idx1-ubyte')\n",
    "\n",
    "# reshape the data so as to fit the format of (samples, height, width, channels)\n",
    "X_train = X_train.reshape(60000, 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(10000, 28, 28, 1).astype('float32')\n",
    "\n",
    "Y_train = Y_train.reshape(60000)\n",
    "Y_test = Y_test.reshape(10000)\n",
    "\n",
    "Y_train = to_categorical(Y_train, 10)\n",
    "Y_test = to_categorical(Y_test, 10)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=20, kernel_size=(6,6), kernel_regularizer=regularizers.l2(0.04), strides=(1,1), padding='valid', activation='relu', data_format='channels_last', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(filters=20, kernel_size=(3,3), kernel_regularizer=regularizers.l2(0.04), strides=(1,1), padding='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4,4), strides=(1,1)))\n",
    "model.add(Dropout(rate=0.05,seed=3))\n",
    "\n",
    "model.add(Conv2D(filters=10, kernel_size=(6,6), kernel_regularizer=regularizers.l2(0.04), strides=(1,1), padding='valid', activation='relu'))\n",
    "model.add(Conv2D(filters=10, kernel_size=(3,3), kernel_regularizer=regularizers.l2(0.04), strides=(1,1), padding='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4,4), strides=(1,1)))\n",
    "model.add(Dropout(rate=0.05,seed=8))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=30, activation='tanh', kernel_regularizer=regularizers.l2(0.04)))\n",
    "model.add(Dense(units=10, activation='softmax', kernel_regularizer=regularizers.l2(0.04)))\n",
    "\n",
    "\n",
    "# reduce the learning rate if training accuracy suddenly drops and keeps decreasing\n",
    "sgd = optimizers.SGD(lr=0.003) # lr by default is 0.01 for SGD\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=[metrics.categorical_accuracy])\n",
    "\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=5, batch_size=50)\n",
    "\n",
    "\n",
    "print(\"\\nEvaluating the model on test data. This won't take long. Relax!\")\n",
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test, batch_size=10)\n",
    "print(\"\\nAccuracy on test data : \", test_accuracy*100)\n",
    "print(\"\\nLoss on test data : \", test_loss)\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
